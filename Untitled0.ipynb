{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "787c1a9d702144b7b0a24817d0b5c04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_498077c8350040b7bc33186e534bfd9e",
              "IPY_MODEL_494f12e9e82847029644e556f50755a9",
              "IPY_MODEL_eaa58536819e4325a2e0868b4fe57349"
            ],
            "layout": "IPY_MODEL_06ac324affb440cda3cf725aa7be27ba"
          }
        },
        "498077c8350040b7bc33186e534bfd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22186e6f2f954040aed44e04ada43f86",
            "placeholder": "​",
            "style": "IPY_MODEL_772f199ffe5c44eb906d59cf854e9750",
            "value": "100%"
          }
        },
        "494f12e9e82847029644e556f50755a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb605e25e494729b2d94cc5bd6f3d84",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd2c1e37b166459784f1dfc630ebafa2",
            "value": 50
          }
        },
        "eaa58536819e4325a2e0868b4fe57349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d45ccf57444c648ae0539da02ca1f8",
            "placeholder": "​",
            "style": "IPY_MODEL_4d7bb90292b14c40a99efd15fc1f3820",
            "value": " 50/50 [00:10&lt;00:00,  4.71it/s]"
          }
        },
        "06ac324affb440cda3cf725aa7be27ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22186e6f2f954040aed44e04ada43f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772f199ffe5c44eb906d59cf854e9750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb605e25e494729b2d94cc5bd6f3d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2c1e37b166459784f1dfc630ebafa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9d45ccf57444c648ae0539da02ca1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d7bb90292b14c40a99efd15fc1f3820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4774e9a0a4347ecbe07730e27f9a83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aa1ea14725c4cdb9f3078327eec2494",
              "IPY_MODEL_7f6a0687bc9e44a09bc2f1161900c630",
              "IPY_MODEL_8d5475fd6e39454c8b622a6bf40e9813"
            ],
            "layout": "IPY_MODEL_cb63c12fe1a64d1dacb8f6a21923833b"
          }
        },
        "7aa1ea14725c4cdb9f3078327eec2494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa963514e194349b3c7132312f65038",
            "placeholder": "​",
            "style": "IPY_MODEL_e39365abf864416d9a6828f5c8d77213",
            "value": "100%"
          }
        },
        "7f6a0687bc9e44a09bc2f1161900c630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c5cf57617f4f37ab21fd67098b474c",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49b7605ecd854b3397d0efca6ca7807c",
            "value": 50
          }
        },
        "8d5475fd6e39454c8b622a6bf40e9813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_334539fb88824db683815d7aaabb585e",
            "placeholder": "​",
            "style": "IPY_MODEL_70b008eef47a40da98fb4ea374186bd9",
            "value": " 50/50 [00:10&lt;00:00,  4.75it/s]"
          }
        },
        "cb63c12fe1a64d1dacb8f6a21923833b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa963514e194349b3c7132312f65038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39365abf864416d9a6828f5c8d77213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3c5cf57617f4f37ab21fd67098b474c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b7605ecd854b3397d0efca6ca7807c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "334539fb88824db683815d7aaabb585e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b008eef47a40da98fb4ea374186bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install detectron 2"
      ],
      "metadata": {
        "id": "jw7UcNnPyvdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1 > /dev/null 2>&1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2' > /dev/null 2>&1\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])} > /dev/null 2>&1\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "fqMyG96ryD7p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install GPT and Stable diffusion"
      ],
      "metadata": {
        "id": "tWwVTdMiBvvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "b_CZNL8Ry5ep"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import cv2\n",
        "import detectron2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer, _create_text_labels\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch import nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "import pathlib\n",
        "\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import mean_squared_error\n",
        "\n",
        "# Import the necessary libraries for partitioning the dataset into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class DetectronGPTDiffusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DetectronGPTDiffusion, self).__init__()\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # Detectron2 parts\n",
        "        # Note that the \"items\" we could detect here are limited to the 80 classes\n",
        "        # of the COCO dataset, but we can add more classes if we want to.\n",
        "        self.cfg = get_cfg()\n",
        "        # add project-specific config (e.g., TensorMask) here if you're not running\n",
        "        # a model in detectron2's core library\n",
        "        self.cfg.merge_from_file(\n",
        "            model_zoo.get_config_file(\n",
        "                \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "            )\n",
        "        )\n",
        "        # Detection threshold for this model\n",
        "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "        # Find a model from detectron2's model zoo.\n",
        "        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "            \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "        )\n",
        "        self.metadata = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0])\n",
        "        # This is the main detectron module\n",
        "        # This has no .parameters() function so we assume it's already frozen\n",
        "        self.detectron = DefaultPredictor(self.cfg)\n",
        "\n",
        "        # GPT-J parts\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\")\n",
        "        self.gpt = AutoModelForCausalLM.from_pretrained(\n",
        "            \"gpt2-large\", cache_dir=pathlib.Path(\"cache\").resolve()\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Diffusion parts\n",
        "        # This has no .parameters() function so we assume it's already frozen\n",
        "        self.diffusion_model = DiffusionPipeline.from_pretrained(\n",
        "            \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16\n",
        "        ).to(self.device)\n",
        "\n",
        "    def partition_image(self, image_dir: str = \"input.jpg\"):\n",
        "        im = cv2.imread(image_dir)\n",
        "        # Round down the image's height and width to the nearest multiple of 8\n",
        "        # (the largest multiple of 8 that is smaller than the image's height and width)\n",
        "        im_height = im.shape[0]\n",
        "        im_width = im.shape[1]\n",
        "        im_height = im_height - (im_height % 8)\n",
        "        im_width = im_width - (im_width % 8)\n",
        "        im = cv2.resize(im, (im_width, im_height))\n",
        "\n",
        "        outputs = self.detectron(im)\n",
        "        predictions = outputs[\"instances\"]\n",
        "\n",
        "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
        "        scores = predictions.scores if predictions.has(\"scores\") else None\n",
        "        classes = (\n",
        "            predictions.pred_classes.tolist()\n",
        "            if predictions.has(\"pred_classes\")\n",
        "            else None\n",
        "        )\n",
        "        labels = _create_text_labels(classes, self.metadata.get(\"thing_classes\", None))\n",
        "        keypoints = (\n",
        "            predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n",
        "        )\n",
        "\n",
        "        return im, [boxes, scores, classes, labels, keypoints]\n",
        "\n",
        "    def gpt_post_process(self, output_sequences, input_prompt):\n",
        "        predictions = []\n",
        "        generated_sequences = []\n",
        "\n",
        "        max_repeat = 2\n",
        "\n",
        "        # decode prediction\n",
        "        for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "            generated_sequence = generated_sequence.tolist()\n",
        "            text = self.tokenizer.decode(\n",
        "                generated_sequence,\n",
        "                clean_up_tokenization_spaces=True,\n",
        "                skip_special_tokens=True,\n",
        "            )\n",
        "            # Take out the prompt given to it by us\n",
        "            text = text[len(input_prompt) :]\n",
        "            generated_sequences.append(text.strip())\n",
        "\n",
        "        for i, g in enumerate(generated_sequences):\n",
        "            res = str(g).replace(\"\\n\\n\\n\", \"\\n\").replace(\"\\n\\n\", \"\\n\")\n",
        "            lines = res.split(\"\\n\")\n",
        "            # # print(lines)\n",
        "            # i = max_repeat\n",
        "            # while i != len(lines):\n",
        "            #   remove_count = 0\n",
        "            #   for index in range(0, max_repeat):\n",
        "            #     # print(i - index - 1, i - index)\n",
        "            #     if lines[i - index - 1] == lines[i - index]:\n",
        "            #       remove_count += 1\n",
        "            #   if remove_count == max_repeat:\n",
        "            #     lines.pop(i)\n",
        "            #     i -= 1\n",
        "            #   else:\n",
        "            #     i += 1\n",
        "            predictions.append(\"\\n\".join(lines))\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    # temp = min:0, max:3, step:0.01\n",
        "    # top_p = # min:0, max:1, step:0.01\n",
        "    # repetition penalty is very critical for GPT-2\n",
        "    # TODO: Move these gpt generation parameters to the __init__ function\n",
        "    def gpt_generate(\n",
        "        self,\n",
        "        prompt,\n",
        "        num_sequences=1,\n",
        "        min_length=128,\n",
        "        max_length=256,\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        top_k=50,\n",
        "        repetition_penalty=1.0,\n",
        "    ):\n",
        "\n",
        "        prompt_full = self.tokenizer(\n",
        "            prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
        "        ).to(self.device)\n",
        "        encoded_prompt = prompt_full.input_ids\n",
        "        encoded_prompt = encoded_prompt.to(self.device)\n",
        "\n",
        "        output_sequences = self.gpt.generate(\n",
        "            input_ids=encoded_prompt,\n",
        "            max_new_tokens=max_length,\n",
        "            attention_mask=prompt_full.attention_mask,\n",
        "            min_length=min_length,\n",
        "            temperature=float(temperature),\n",
        "            top_p=float(top_p),\n",
        "            top_k=int(top_k),\n",
        "            do_sample=True,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            num_return_sequences=num_sequences,\n",
        "        )\n",
        "\n",
        "        return self.gpt_post_process(output_sequences, prompt)\n",
        "\n",
        "    def generate_image(self, prompt, height=256, width=256):\n",
        "        max_length = self.diffusion_model.tokenizer.model_max_length\n",
        "        input_ids = self.diffusion_model.tokenizer(\n",
        "            prompt, return_tensors=\"pt\"\n",
        "        ).input_ids\n",
        "        input_ids = input_ids.to(self.device)\n",
        "\n",
        "        negative_ids = self.diffusion_model.tokenizer(\n",
        "            \"\",\n",
        "            truncation=False,\n",
        "            padding=\"max_length\",\n",
        "            max_length=input_ids.shape[-1],\n",
        "            return_tensors=\"pt\",\n",
        "        ).input_ids\n",
        "        negative_ids = negative_ids.to(self.device)\n",
        "\n",
        "        concat_embeds = []\n",
        "        neg_embeds = []\n",
        "        for i in range(0, input_ids.shape[-1], max_length):\n",
        "            concat_embeds.append(\n",
        "                self.diffusion_model.text_encoder(input_ids[:, i : i + max_length])[0]\n",
        "            )\n",
        "            neg_embeds.append(\n",
        "                self.diffusion_model.text_encoder(negative_ids[:, i : i + max_length])[\n",
        "                    0\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        prompt_embeds = torch.cat(concat_embeds, dim=1)\n",
        "        negative_prompt_embeds = torch.cat(neg_embeds, dim=1)\n",
        "\n",
        "        return self.diffusion_model(\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            height=height,\n",
        "            width=width,\n",
        "        ).images\n",
        "\n",
        "    def generate_description(self, boxes, labels):\n",
        "        full_str = \"\"\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes[i]\n",
        "            label = labels[i]\n",
        "            box_array = box.tensor.flatten().tolist()\n",
        "            # Just the pixel is enough, no floating points\n",
        "            box_array = [int(x) for x in box_array]\n",
        "            full_str += f\"a {label} at {box_array}, \"\n",
        "        return full_str\n",
        "\n",
        "    def forward(self, image_dir: str):\n",
        "        input_image, [\n",
        "            boxes,\n",
        "            scores,\n",
        "            classes,\n",
        "            labels,\n",
        "            keypoints,\n",
        "        ] = self.partition_image(image_dir)\n",
        "        height = input_image.shape[0]\n",
        "        width = input_image.shape[1]\n",
        "        description = self.generate_description(boxes, labels)\n",
        "        prompt = (\n",
        "            \"We would like to generate a text prompt that will be used to generate an image. In this image, [a, b, c, d] represents the position of the object in the image. In the prompt, describe the objects to be included as well as their positions.\"  # noqa: E501\n",
        "            + description\n",
        "        )\n",
        "        engineered_prompt = self.gpt_generate(prompt)[0]\n",
        "        output_image = self.generate_image(engineered_prompt, height, width)[0]\n",
        "\n",
        "        return {\n",
        "            \"manual_prompt\": prompt,\n",
        "            \"output_prompt\": engineered_prompt,\n",
        "            \"input_image\": input_image,\n",
        "            \"output_image\": output_image,\n",
        "        }\n",
        "\n",
        "\n",
        "def _create_text_labels(classes, class_names, is_crowd=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        classes (list[int] or None):\n",
        "        scores (list[float] or None):\n",
        "        class_names (list[str] or None):\n",
        "        is_crowd (list[bool] or None):\n",
        "\n",
        "    Returns:\n",
        "        list[str] or None\n",
        "    \"\"\"\n",
        "    labels = None\n",
        "    if classes is not None:\n",
        "        if class_names is not None and len(class_names) > 0:\n",
        "            labels = [class_names[i] for i in classes]\n",
        "        else:\n",
        "            labels = [str(i) for i in classes]\n",
        "\n",
        "    if labels is not None and is_crowd is not None:\n",
        "        labels = [l + (\"|crowd\" if crowd else \"\") for l, crowd in zip(labels, is_crowd)]\n",
        "    return labels"
      ],
      "metadata": {
        "id": "dCNCB8e6zL6d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnHGWBSQnV2j",
        "outputId": "7ddaf7d5-6942-411f-ea0a-d32c16f892c6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.72 ms (started: 2023-06-04 04:14:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiZm-fMjnPjo",
        "outputId": "4d5f23d4-1fc7-4fd2-aef0-5d4192d3f798"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n",
            "time: 6.85 s (started: 2023-06-04 04:14:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
        "im_transform = transforms.ToTensor()\n",
        "\n",
        "def ssim_loss(input_image, output_image):\n",
        "    # Calculate the score between the input and output images\n",
        "    input_torch = im_transform(input_image)\n",
        "    output_torch = im_transform(output_image)\n",
        "    score = ssim(input_torch, output_torch)\n",
        "    return 1 - score\n",
        "\n",
        "\n",
        "# A function which returns the filenames of all the images in a directory\n",
        "def get_image_filenames(directory):\n",
        "    # Get all the filenames\n",
        "    filenames = os.listdir(directory)\n",
        "    # Filter out the non-image files\n",
        "    filenames = [f for f in filenames if f.endswith(\".jpg\")]\n",
        "    # Add the directory to the filenames\n",
        "    filenames = [os.path.join(directory, f) for f in filenames]\n",
        "    return filenames\n",
        "\n",
        "\n",
        "# Optimize the parameters of the gpt part of the model\n",
        "def optimize_gpt(\n",
        "    model: DetectronGPTDiffusion,\n",
        "    num_steps=10,\n",
        "    learning_rate=0.01,\n",
        "):\n",
        "    # Get the dataset\n",
        "    dataset = get_image_filenames(\n",
        "        \"/content/drive/Shareddrives/COM SCI 263/Final Project/Data/COCO/val2017\"\n",
        "    )[:num_steps]\n",
        "    # We use run the model one time for each image in the dataset\n",
        "    # (Filtered to only n_steps images)\n",
        "    test, train = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = torch.optim.Adam(\n",
        "        [\n",
        "            {\n",
        "                \"params\": model.gpt.parameters(),\n",
        "                \"lr\": learning_rate,\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Optimize the parameters\n",
        "    for i in range(num_steps):\n",
        "        # Reset the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        model_output = model.forward(train[i])\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = ssim_loss(model_output[\"input_image\"], model_output[\"output_image\"])\n",
        "\n",
        "        # Print the loss\n",
        "        print(f\"Step: {i}, Loss: {loss}\")\n",
        "\n",
        "        # Backpropagate the loss\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1XtYSSzi_71",
        "outputId": "a5aa826d-9333-469c-9b6f-bf61c1a705d9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.71 ms (started: 2023-06-04 04:15:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del pipeline"
      ],
      "metadata": {
        "id": "Rha8HD-y7X17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "3f68562b-d44e-4118-d559-6eff9cf546fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-714803d05d40>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = DetectronGPTDiffusion()"
      ],
      "metadata": {
        "id": "n7U-aXZgzXLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d718e4e9-e86f-4072-e6c9-92d6c683a1c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O 'input.jpg'\n",
        "im = cv2.imread(\"./input.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "metadata": {
        "id": "DnvKPVRY-4M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = cv2.imread(\"./input.jpg\")\n",
        "type(im)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHRuY-zrkO7o",
        "outputId": "c65d241e-16b6-4319-8661-2a261fd80057"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 51.8 ms (started: 2023-06-04 04:02:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_transform(im).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQUuEoWwlNaU",
        "outputId": "c5f9932e-824e-4a1a-c445-1c1cca79d915"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 480, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.4 ms (started: 2023-06-04 04:05:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "q3nECc8Wevpl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do a single run of the whole model and time it."
      ],
      "metadata": {
        "id": "M3j5OhXJiNmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autotime\n",
        "out_dict = pipeline.forward(\"./input.jpg\")"
      ],
      "metadata": {
        "id": "eb0bLLCW52F6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "787c1a9d702144b7b0a24817d0b5c04f",
            "498077c8350040b7bc33186e534bfd9e",
            "494f12e9e82847029644e556f50755a9",
            "eaa58536819e4325a2e0868b4fe57349",
            "06ac324affb440cda3cf725aa7be27ba",
            "22186e6f2f954040aed44e04ada43f86",
            "772f199ffe5c44eb906d59cf854e9750",
            "fbb605e25e494729b2d94cc5bd6f3d84",
            "fd2c1e37b166459784f1dfc630ebafa2",
            "b9d45ccf57444c648ae0539da02ca1f8",
            "4d7bb90292b14c40a99efd15fc1f3820"
          ]
        },
        "outputId": "81598c9c-e8a5-48a7-c82b-6676db76cb6f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "787c1a9d702144b7b0a24817d0b5c04f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 22.2 s (started: 2023-06-04 04:06:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the output image"
      ],
      "metadata": {
        "id": "QThj4KBiiTa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(out_dict[\"output_image\"])"
      ],
      "metadata": {
        "id": "5Uw0s2_D_frp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49875c07-7dfe-4c3b-a5fb-7159b063c5aa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.74 ms (started: 2023-06-04 04:08:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_transform(out_dict[\"input_image\"])"
      ],
      "metadata": {
        "id": "HFiGPWZ_l7Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_transform(out_dict[\"output_image\"])"
      ],
      "metadata": {
        "id": "Pc7ORyynl3x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssim_loss(out_dict[\"input_image\"], out_dict[\"output_image\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "Pvx1_83Tnm02",
        "outputId": "f2915bd3-5eb8-483d-abd8-7dd7058fa2a5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mssim_loss\u001b[0m:\u001b[94m9\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/image/\u001b[0m\u001b[1;33mssim.py\u001b[0m:\u001b[94m263\u001b[0m in             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mstructural_similarity_index_measure\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m>>> structural_similarity_index_measure(preds, target)\u001b[0m                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mtensor(0.9219)\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m263 \u001b[2m│   \u001b[0mpreds, target = _ssim_check_inputs(preds, target)                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   \u001b[0msimilarity_pack = _ssim_update(                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   \u001b[0mpreds,                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0mtarget,                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/image/\u001b[0m\u001b[1;33mssim.py\u001b[0m:\u001b[94m39\u001b[0m in              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92m_ssim_check_inputs\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   \u001b[0mtarget = target.to(preds.dtype)                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 37 \u001b[0m\u001b[2m│   \u001b[0m_check_same_shape(preds, target)                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 38 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(preds.shape) \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m (\u001b[94m4\u001b[0m, \u001b[94m5\u001b[0m):                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 39 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mExpected `preds` and `target` to have BxCxHxW or BxCxDxHxW shape.\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m Got preds: \u001b[0m\u001b[33m{\u001b[0mpreds.shape\u001b[33m}\u001b[0m\u001b[33m and target: \u001b[0m\u001b[33m{\u001b[0mtarget.shape\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mValueError: \u001b[0mExpected `preds` and `target` to have BxCxHxW or BxCxDxHxW shape. Got preds: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m480\u001b[0m, \u001b[1;36m640\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \n",
              "and target: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m480\u001b[0m, \u001b[1;36m640\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ssim_loss</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/image/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ssim.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">263</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">structural_similarity_index_measure</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">&gt;&gt;&gt; structural_similarity_index_measure(preds, target)</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tensor(0.9219)</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>263 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>preds, target = _ssim_check_inputs(preds, target)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   </span>similarity_pack = _ssim_update(                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   </span>preds,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 │   │   </span>target,                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/image/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ssim.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">39</span> in              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_ssim_check_inputs</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 │   │   </span>target = target.to(preds.dtype)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 37 │   </span>_check_same_shape(preds, target)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 38 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(preds.shape) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 39 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Expected `preds` and `target` to have BxCxHxW or BxCxDxHxW shape.\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" Got preds: {</span>preds.shape<span style=\"color: #808000; text-decoration-color: #808000\">} and target: {</span>target.shape<span style=\"color: #808000; text-decoration-color: #808000\">}.\"</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Expected `preds` and `target` to have BxCxHxW or BxCxDxHxW shape. Got preds: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span><span style=\"font-weight: bold\">])</span> \n",
              "and target: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span><span style=\"font-weight: bold\">])</span>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 139 ms (started: 2023-06-04 04:16:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive"
      ],
      "metadata": {
        "id": "SDh6WensiWLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C-xEKsHCRCyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b2cff6-4e22-4f3b-b612-c93423a8564a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset and unzip it"
      ],
      "metadata": {
        "id": "-7N8Dj3YiYOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P '/content/drive/Shareddrives/COM SCI 263/Final Project/Data/COCO' http://images.cocodataset.org/zips/val2017.zip\n",
        "!cd '/content/drive/Shareddrives/COM SCI 263/Final Project/Data/COCO' && unzip val2017.zip > /dev/null 2>&1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsYPzXM2dAUA",
        "outputId": "7219697e-b414-4e1d-a95c-8aced0646c17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-04 03:30:56--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.25.154, 54.231.235.209, 52.216.41.25, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.25.154|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘/content/drive/Shareddrives/COM SCI 263/Final Project/Data/COCO/val2017.zip’\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  37.4MB/s    in 16s     \n",
            "\n",
            "2023-06-04 03:31:12 (47.3 MB/s) - ‘/content/drive/Shareddrives/COM SCI 263/Final Project/Data/COCO/val2017.zip’ saved [815585330/815585330]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, optimize the GPT!"
      ],
      "metadata": {
        "id": "qC3mbNgnit2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autotime\n",
        "optimize_gpt(pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735,
          "referenced_widgets": [
            "e4774e9a0a4347ecbe07730e27f9a83e",
            "7aa1ea14725c4cdb9f3078327eec2494",
            "7f6a0687bc9e44a09bc2f1161900c630",
            "8d5475fd6e39454c8b622a6bf40e9813",
            "cb63c12fe1a64d1dacb8f6a21923833b",
            "cfa963514e194349b3c7132312f65038",
            "e39365abf864416d9a6828f5c8d77213",
            "d3c5cf57617f4f37ab21fd67098b474c",
            "49b7605ecd854b3397d0efca6ca7807c",
            "334539fb88824db683815d7aaabb585e",
            "70b008eef47a40da98fb4ea374186bd9"
          ]
        },
        "id": "Lc5dHRDpdmpK",
        "outputId": "f5b89977-9f17-4c99-bdcf-6a32019a4326"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4774e9a0a4347ecbe07730e27f9a83e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 2>\u001b[0m:\u001b[94m2\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92moptimize_gpt\u001b[0m:\u001b[94m55\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mssim_loss\u001b[0m:\u001b[94m8\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/skimage/_shared/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m348\u001b[0m in \u001b[92mfixed_func\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mkwargs[\u001b[33m'\u001b[0m\u001b[33mchannel_axis\u001b[0m\u001b[33m'\u001b[0m] = convert[kwargs.pop(\u001b[33m'\u001b[0m\u001b[33mmultichannel\u001b[0m\u001b[33m'\u001b[0m)]               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m346 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Call the function with the fixed arguments\u001b[0m                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m348 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m349 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m350 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m func.\u001b[91m__doc__\u001b[0m \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   │   │   \u001b[0mnewdoc = docstring_add_deprecated(                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/skimage/metrics/\u001b[0m\u001b[1;33m_structural_similarity.py\u001b[0m:\u001b[94m102\u001b[0m in         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mstructural_similarity\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   \u001b[0mcheck_shape_equality(im1, im2)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m102 \u001b[2m│   \u001b[0mfloat_type = _supported_float_type(im1.dtype)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m channel_axis \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# loop over channels\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/skimage/_shared/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m802\u001b[0m in \u001b[92m_supported_float_type\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m799 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m800 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(input_dtype, Iterable) \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(input_dtype, \u001b[96mstr\u001b[0m):             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m801 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m np.result_type(*(_supported_float_type(d) \u001b[94mfor\u001b[0m d \u001b[95min\u001b[0m input_dtype))            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m802 \u001b[2m│   \u001b[0minput_dtype = np.dtype(input_dtype)                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m803 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m allow_complex \u001b[95mand\u001b[0m input_dtype.kind == \u001b[33m'\u001b[0m\u001b[33mc\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m804 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mcomplex valued input is not supported\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m805 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m new_float_type.get(input_dtype.char, np.float64)                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mTypeError: \u001b[0mCannot interpret \u001b[32m'torch.float32'\u001b[0m as a data type\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 2&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimize_gpt</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">55</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ssim_loss</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/skimage/_shared/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">348</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fixed_func</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">345 │   │   │   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">'channel_axis'</span>] = convert[kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">'multichannel'</span>)]               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347 │   │   │   # Call the function with the fixed arguments</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>348 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">350 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> func.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__doc__</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">351 │   │   │   </span>newdoc = docstring_add_deprecated(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/skimage/metrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_structural_similarity.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">102</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">structural_similarity</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 │   </span>check_shape_equality(im1, im2)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>102 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>float_type = _supported_float_type(im1.dtype)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> channel_axis <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 │   │   # loop over channels</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/skimage/_shared/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">802</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_supported_float_type</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">799 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">800 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(input_dtype, Iterable) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(input_dtype, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">801 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> np.result_type(*(_supported_float_type(d) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> d <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> input_dtype))            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>802 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>input_dtype = np.dtype(input_dtype)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">803 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> allow_complex <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> input_dtype.kind == <span style=\"color: #808000; text-decoration-color: #808000\">'c'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">804 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"complex valued input is not supported\"</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">805 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> new_float_type.get(input_dtype.char, np.float64)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>Cannot interpret <span style=\"color: #008000; text-decoration-color: #008000\">'torch.float32'</span> as a data type\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 22.3 s (started: 2023-06-04 04:09:09 +00:00)\n"
          ]
        }
      ]
    }
  ]
}